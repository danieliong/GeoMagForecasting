# @package _global_

model: xgboost

# TODO: Find way to separate this into new file
hydra:
  # launcher:
  #   mem_gb: 15
  #   cpus_per_task: 1
  #   additional_parameters:
  #     account: stats_dept1
  sweeper:
    optim:
      optimizer: NGOpt
      budget: 3
      num_workers: 1
    parametrization:
      param.learning_rate:
        # init: 0.2
        lower: 0.001
        upper: 0.6
      param.max_depth:
        integer: true
        # init: 6
        lower: 1
        upper: 9
      param.min_child_weight:
        integer: true
        # init: 2
        lower: 1
        upper: 4
      param.colsample_bytree:
        # init: 0.8
        lower: 0.5
        upper: 1.0
      param.rate_drop:
        init: 0.1
        lower: 0.0
        upper: 0.5
      param.skip_drop:
        init: 0.5
        lower: 0.25
        upper: 0.75

tune:
  experiment_name: null
  experiment_id: null
  lags: false
  metric: "rmse"
  # filter_string: "params.features=\"['bx', 'by', 'bz']\""
  filter_string: ""
  # filter_string: "params.features=\"['bx', 'by', 'bz']\""
  # filter_string: "params.lag=\"0\""
  params:
    - learning_rate
    - max_depth
    - min_child_weight
    - colsample_bytree
    - rate_drop
    - skip_drop
  kwargs:
    - num_boost_round

param:
  learning_rate: 0.2
  max_depth: 6
  min_child_weight: 2
  colsample_bytree: 0.8
  booster: "dart"
  rate_drop: 0.1
  skip_drop: 0.5

mlflow: true

kwargs:
  num_boost_round: 500
  early_stopping_rounds: 10

outputs:
  model: "model.xgb"
  cv_table: "cv_table.csv"
  cv_results: "cv_results.yaml"
